{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facenet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "binbOwuvP-nG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.decomposition import PCA\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from mpl_toolkits.mplot3d import proj3d\n",
        "from imageio import imread\n",
        "from skimage.transform import resize\n",
        "from scipy.spatial import distance\n",
        "from keras.models import load_model\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Sample data/train_relationships.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Sample data/sample_submission.csv\")"
      ],
      "metadata": {
        "id": "9bBDv_gDRrPT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/keras-facenet/model/facenet_keras.h5'\n",
        "model = load_model(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtkTxpxBSBl5",
        "outputId": "a7b9d0db-0ece-4a61-cf74-03e9a04b4337"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prewhiten(x):\n",
        "    if x.ndim == 4:\n",
        "        axis = (1, 2, 3)\n",
        "        size = x[0].size\n",
        "    elif x.ndim == 3:\n",
        "        axis = (0, 1, 2)\n",
        "        size = x.size\n",
        "    else:\n",
        "        raise ValueError('Dimension should be 3 or 4')\n",
        "\n",
        "    mean = np.mean(x, axis=axis, keepdims=True)\n",
        "    std = np.std(x, axis=axis, keepdims=True)\n",
        "    std_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
        "    y = (x - mean) / std_adj\n",
        "    return y\n",
        "\n",
        "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
        "    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n",
        "    return output\n",
        "def load_and_align_images(filepaths, margin,image_size = 160):\n",
        "    \n",
        "    aligned_images = []\n",
        "    for filepath in filepaths:\n",
        "        img = imread(filepath)\n",
        "        aligned = resize(img, (image_size, image_size), mode='reflect')\n",
        "        aligned_images.append(aligned)\n",
        "            \n",
        "    return np.array(aligned_images)"
      ],
      "metadata": {
        "id": "iaR3wnawSPNW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_embs(filepaths, margin=10, batch_size=512):\n",
        "    pd = []\n",
        "    for start in tqdm(range(0, len(filepaths), batch_size)):\n",
        "        aligned_images = prewhiten(load_and_align_images(filepaths[start:start+batch_size], margin))\n",
        "        pd.append(model.predict_on_batch(aligned_images))\n",
        "    embs = l2_normalize(np.concatenate(pd))\n",
        "\n",
        "    return embs"
      ],
      "metadata": {
        "id": "MXXG_AcUSnur"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = os.listdir(\"/content/drive/MyDrive/Sample data/test_images\")\n",
        "test_embs = calc_embs([os.path.join(\"/content/drive/MyDrive/Sample data/test_images\", f) for f in test_images])\n",
        "np.save(\"test_embs.npy\", test_embs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EthwXjYSrk_",
        "outputId": "52a84e9b-5d04-4d9c-c48a-09a070573032"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [03:24<00:00, 15.74s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[\"distance\"] = 0\n",
        "img2idx = dict()\n",
        "for idx, img in enumerate(test_images):\n",
        "    img2idx[img] = idx"
      ],
      "metadata": {
        "id": "hjTUhxZqS5et"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
        "    imgs = [test_embs[img2idx[img]] for img in row.img_pair.split(\"-\")]\n",
        "    test_df.loc[idx, \"distance\"] = distance.euclidean(*imgs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U-w0IRSVXHe",
        "outputId": "15a84794-562f-4849-d520-8321d5f932b1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5310/5310 [00:02<00:00, 1815.42it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_distances = test_df.distance.values\n",
        "sum_dist = np.sum(all_distances)"
      ],
      "metadata": {
        "id": "tPamUTN4VbW3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = []\n",
        "for dist in tqdm(all_distances):\n",
        "    prob = np.sum(all_distances[np.where(all_distances <= dist)[0]])/sum_dist\n",
        "    probs.append(1 - prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEDS-TO1Vfu0",
        "outputId": "114fa811-0267-4f61-cab1-7b4955f58fd2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5310/5310 [00:00<00:00, 23417.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_df = pd.read_csv(\"/content/drive/MyDrive/Sample data/sample_submission.csv\")\n",
        "sub_df.is_related = probs\n",
        "sub_df.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "Jhnr2qkaVizE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LVjkcgs4kOpw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}